{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4fea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "import string\n",
    "import numpy as np\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "#from skimage import io\n",
    "import os\n",
    "import matplotlib\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958d85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#----------------------------\n",
    "#label object\n",
    "def label_object(image, apple, textsize, thickness, xmax, xmid, xmin, ymax, ymid, ymin):\n",
    "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), DARK_BLUE, thickness)\n",
    "    pos = (xmid - textsize[0]//2, ymid + textsize[1]//2)\n",
    "    cv2.putText(image, apple, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, YELLOW, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "#Tracking\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def linear_assignment(cost_matrix):\n",
    "  try:\n",
    "    import lap\n",
    "    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "    return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "  except ImportError:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    x, y = linear_sum_assignment(cost_matrix)\n",
    "    return np.array(list(zip(x, y)))\n",
    "\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "  \"\"\"\n",
    "  From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "  \"\"\"\n",
    "  bb_gt = np.expand_dims(bb_gt, 0)\n",
    "  bb_test = np.expand_dims(bb_test, 1)\n",
    "  \n",
    "  xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "  yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "  xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "  yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "  w = np.maximum(0., xx2 - xx1)\n",
    "  h = np.maximum(0., yy2 - yy1)\n",
    "  wh = w * h\n",
    "  o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "  return(o)  \n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "  \"\"\"\n",
    "  w = np.sqrt(x[2] * x[3])\n",
    "  h = x[2] / w\n",
    "  if(score==None):\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "  else:\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.time_since_update = 0\n",
    "    self.id = KalmanBoxTracker.count\n",
    "    KalmanBoxTracker.count += 1\n",
    "    self.history = []\n",
    "    self.hits = 0\n",
    "    self.hit_streak = 0\n",
    "    self.age = 0\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.time_since_update = 0\n",
    "    self.history = []\n",
    "    self.hits += 1\n",
    "    self.hit_streak += 1\n",
    "    self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "\n",
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "  \"\"\"\n",
    "  Assigns detections to tracked object (both represented as bounding boxes)\n",
    "  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "  \"\"\"\n",
    "  if(len(trackers)==0):\n",
    "    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "  iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "  if min(iou_matrix.shape) > 0:\n",
    "    a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "        matched_indices = np.stack(np.where(a), axis=1)\n",
    "    else:\n",
    "      matched_indices = linear_assignment(-iou_matrix)\n",
    "  else:\n",
    "    matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "  unmatched_detections = []\n",
    "  for d, det in enumerate(detections):\n",
    "    if(d not in matched_indices[:,0]):\n",
    "      unmatched_detections.append(d)\n",
    "  unmatched_trackers = []\n",
    "  for t, trk in enumerate(trackers):\n",
    "    if(t not in matched_indices[:,1]):\n",
    "      unmatched_trackers.append(t)\n",
    "\n",
    "  #filter out matched with low IOU\n",
    "  matches = []\n",
    "  for m in matched_indices:\n",
    "    if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "      unmatched_detections.append(m[0])\n",
    "      unmatched_trackers.append(m[1])\n",
    "    else:\n",
    "      matches.append(m.reshape(1,2))\n",
    "  if(len(matches)==0):\n",
    "    matches = np.empty((0,2),dtype=int)\n",
    "  else:\n",
    "    matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class Sort(object):\n",
    "  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Sets key parameters for SORT\n",
    "    \"\"\"\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers = []\n",
    "    self.frame_count = 0\n",
    "\n",
    "  def update(self, dets=np.empty((0, 5))):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks = np.zeros((len(self.trackers), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "    for t in reversed(to_del):\n",
    "      self.trackers.pop(t)\n",
    "    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "\n",
    "    # update matched trackers with assigned detections\n",
    "    for m in matched:\n",
    "      self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "    # create and initialise new trackers for unmatched detections\n",
    "    for i in unmatched_dets:\n",
    "        trk = KalmanBoxTracker(dets[i,:])\n",
    "        self.trackers.append(trk)\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0]\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "      return np.concatenate(ret)\n",
    "    return np.empty((0,5))\n",
    "\n",
    "#---------------------\n",
    "\n",
    "#string comparison\n",
    "def cmp(a, b):\n",
    "    return [c for c in a if c.isalnum()] == [c for c in b if c.isalnum()]\n",
    "\n",
    "#Substring\n",
    "def check(string, sub_str):\n",
    "    if (string.find(sub_str) == -1):\n",
    "        print(\"NO\")\n",
    "    else:\n",
    "        print(\"YES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07f45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE = (255, 255, 255)\n",
    "YELLOW = (66, 244, 238)\n",
    "GREEN = (80, 220, 60)\n",
    "LIGHT_CYAN = (255, 255, 224)\n",
    "DARK_BLUE = (139, 0, 0)\n",
    "GRAY = (128, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfiguration = \"yolov4-obj.cfg\"\n",
    "modelWeights = \"yolov4-obj_last.weights\"\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CUDA)\n",
    "plates = 0\n",
    "trackers = []\n",
    "counters = {\n",
    "    'lost_trackers': 0,\n",
    "    'frames': 0,\n",
    "}\n",
    "\n",
    "count = {}\n",
    "c = 1\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale = 1\n",
    "thickness = 3\n",
    "final=[]\n",
    "font=cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "\n",
    "tracker = Sort(max_age = np.inf , min_hits=np.inf , iou_threshold = 0.2)\n",
    "classes=['Person']\n",
    "cap = cv2.VideoCapture(\"video.avi\")\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "result = cv2.VideoWriter('output_final.mp4', fourcc, 20.0, (frame_width,frame_height))\n",
    "while True:\n",
    "    start=time.time()\n",
    "    ret, img = cap.read()\n",
    "    counters['frames'] += 1\n",
    "    if not ret:\n",
    "        break\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img,(0,0),fx=0.5,fy=0.5)\n",
    "        height, width, _ = img.shape\n",
    "        if counters[\"frames\"] >= 0:\n",
    "            blob = cv2.dnn.blobFromImage(img, 1/255, (320,320), [0, 0, 0], 1, crop=False)\n",
    "            net.setInput(blob)\n",
    "            output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "            layerOutputs = net.forward(output_layers_names)\n",
    "            boxes = []\n",
    "            confidences = []\n",
    "            class_ids = []\n",
    "            for output in layerOutputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.5:\n",
    "                        center_x = int(detection[0]*width)\n",
    "                        center_y = int(detection[1]*height)\n",
    "                        w = int(detection[2]*width)\n",
    "                        h = int(detection[3]*height)\n",
    "                        x = abs(int(center_x - w/2))\n",
    "                        y = abs(int(center_y - h/2))\n",
    "                        boxes.append([x, y, w, h])\n",
    "                        confidences.append(float(confidence))\n",
    "                        class_ids.append(class_id)\n",
    "        if len(boxes) == 0:\n",
    "            key = cv2.waitKey(1)\n",
    "            if(len(final)!=0):\n",
    "                cv2.putText(img , str(final) , (30 , 50) , font, 1 , LIGHT_CYAN , 2 )\n",
    "            \n",
    "            cv2.imshow('Image', img)\n",
    "            img = cv2.resize(img,(0,0),fx=2,fy=2)\n",
    "            result.write(img)\n",
    "            if key & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "        else:\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "            if len(indexes) > 0:\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                objects = []\n",
    "                colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "                for i in indexes.flatten():\n",
    "                    x , y , w , h , score = [abs(a) for a in boxes[i]] + [confidences[i]]\n",
    "                    #plate=img[y:y+h,x:x+w]\n",
    "                    \n",
    "                    objects.append([x , y , x+w , y+h , score])\n",
    "                objects = np.array(objects)\n",
    "                for obj in objects:\n",
    "                    xmin  , ymin , xmax , ymax , score = obj\n",
    "\n",
    "               \n",
    "                bboxes = tracker.update(objects)\n",
    "                assert len(bboxes) == len(objects)\n",
    "                for b in bboxes:\n",
    "                    x , y , w , h , id = b\n",
    "                    xmin = int(x)\n",
    "                    ymin = int(y)\n",
    "                    xmax = int(w)\n",
    "                    ymax = int(h)\n",
    "                    xmid = int(round((xmin+xmax)/2))\n",
    "                    ymid = int(round((ymin+ymax)/2))\n",
    "                    \n",
    "                    if id not in count:\n",
    "                        count[id] = c\n",
    "                        c += 1\n",
    "\n",
    "                    if count[id] > plates:\n",
    "                        plates = int(count[id])\n",
    "\n",
    "                    textsize, _= cv2.getTextSize(\n",
    "                                        str(int(count[id])), fontface, fontscale, thickness)\n",
    "                    \n",
    "                    #print(\"id\" , count[id])\n",
    "                \n",
    "                    label_object(img , str(int(count[id])) , textsize , thickness , xmax , xmid , xmin , ymax , ymid , ymin)\n",
    "                if(len(final)!=0):\n",
    "                    cv2.putText(img , str(final) , (10 , 50) , font, 1 , LIGHT_CYAN , 2)\n",
    "                cv2.imshow(\"Image\", img)\n",
    "                key = cv2.waitKey(1)\n",
    "                img = cv2.resize(img,(0,0),fx=2,fy=2)\n",
    "                result.write(img)\n",
    "                if key & 0xFF == ord('q'):\n",
    "                    break\n",
    "result.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fddd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
